{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0ydZA32Qmu3C"
      },
      "outputs": [],
      "source": [
        "!pip install chronos-forecasting\n",
        "!pip install transformers==4.40.2\n",
        "!pip install timeseriesviz\n",
        "\n",
        "import torch\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import json\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "from chronos import BaseChronosPipeline, ChronosBoltPipeline\n",
        "from tqdm import tqdm\n",
        "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
        "from csv import reader, writer\n",
        "from timeseriesviz import plot_numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ckpt_name = f\"CamelsUS-chronos-ckpt\"\n",
        "run_name = f\"CamelsUS-chronos\"\n",
        "\n",
        "Restorefromcheckpoint = True"
      ],
      "metadata": {
        "id": "LMDqrql5FXDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def restoreValLocs(ValidationRunName):\n",
        "    InputFileName = APPLDIR + 'Validation' + ValidationRunName\n",
        "    with open(InputFileName, 'r', newline='') as inputfile:\n",
        "        Myreader = reader(inputfile, delimiter=',')\n",
        "        header = next(Myreader)\n",
        "        LocationValidationFraction = np.float32(header[0])\n",
        "        TrainingNloc = np.int32(header[1])\n",
        "        ValidationNloc = np.int32(header[2])\n",
        "\n",
        "        ListofTrainingLocs = np.empty(TrainingNloc, dtype = np.int32)\n",
        "        ListofValidationLocs = np.empty(ValidationNloc,  dtype = np.int32)\n",
        "        nextrow = next(Myreader)\n",
        "        for iloc in range(0, TrainingNloc):\n",
        "            ListofTrainingLocs[iloc] = np.int32(nextrow[iloc])\n",
        "        nextrow = next(Myreader)\n",
        "        for iloc in range(0, ValidationNloc):\n",
        "            ListofValidationLocs[iloc] = np.int32(nextrow[iloc])\n",
        "\n",
        "\n",
        "    return TrainingNloc, ValidationNloc, ListofTrainingLocs, ListofValidationLocs\n",
        "\n",
        "\n",
        "def saveCkpt(iloc, ground_truth, preds, run_name, ckpt_name):\n",
        "    OutputFileName = APPLDIR + ckpt_name\n",
        "    with open(OutputFileName, 'w', newline='') as outputfile:\n",
        "        Mywriter = writer(outputfile, delimiter=',')\n",
        "        Mywriter.writerow([iloc])\n",
        "\n",
        "    np.save(APPLDIR + f\"{run_name}_yin.npy\", ground_truth)\n",
        "    np.save(APPLDIR + f\"{run_name}_FitPredictions.npy\", preds)\n",
        "\n",
        "\n",
        "def restoreCkpt(run_name, ckpt_name):\n",
        "    InputFileName = APPLDIR + ckpt_name\n",
        "    with open(InputFileName, 'r', newline='') as inputfile:\n",
        "        Myreader = reader(inputfile, delimiter=',')\n",
        "        iloc = next(Myreader)[0]\n",
        "\n",
        "    ground_truth = np.load(APPLDIR + f\"{run_name}_yin.npy\", allow_pickle=True)\n",
        "    preds = np.load(APPLDIR + f\"{run_name}_FitPredictions.npy\", allow_pickle=True)\n",
        "\n",
        "    return int(iloc), ground_truth, preds"
      ],
      "metadata": {
        "id": "CmfP1B76HI1D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "APPLDIR = \"/content/gdrive/My Drive/Colab Datasets/Hydrology/\"\n",
        "ValidationRunName = 'Hydrology-CamelsUS-anushka'\n",
        "\n",
        "# Define the file name and file path\n",
        "timeseries_file = 'BasicInputTimeSeries.npy'\n",
        "static_file = 'BasicInputStaticProps.npy'\n",
        "metadata_file = 'metadata.json'\n",
        "\n",
        "timeseries_data = np.load(APPLDIR + timeseries_file, allow_pickle=True)\n",
        "static_data = np.load(APPLDIR + static_file, allow_pickle=True)\n",
        "\n",
        "# Metadata\n",
        "with open(APPLDIR + metadata_file, 'r') as f:\n",
        "    metadata = json.load(f)\n",
        "\n",
        "TrainingNloc, ValidationNloc, ListofTrainingLocs, ListofValidationLocs = restoreValLocs(ValidationRunName)\n",
        "ListofTrainingLocs = [metadata['locs'][i] for i in ListofTrainingLocs]\n",
        "ListofValidationLocs = [metadata['locs'][i] for i in ListofValidationLocs]"
      ],
      "metadata": {
        "id": "8cBDJOivm1Zk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Prepare input\n",
        "timeseries_cols = metadata['BasicInputTimeSeries']['fields']\n",
        "static_cols = metadata['BasicInputStaticProps']['fields']\n",
        "\n",
        "# Create the DataFrame\n",
        "df_timeseries = pd.DataFrame(timeseries_data, columns=timeseries_cols)\n",
        "df_static = pd.DataFrame(static_data, columns=static_cols)\n",
        "\n",
        "df_timeseries['ds'] = pd.to_datetime(df_timeseries['Year_Mnth_Day'])\n",
        "df_timeseries['unique_id'] = df_timeseries['basin_id']\n",
        "df_static = df_static.rename(columns={\"gauge_id\": \"basin_id\"})\n",
        "merged_df = pd.merge(df_timeseries, df_static, on='basin_id', how='inner')\n",
        "merged_df.drop(['Year_Mnth_Day', 'basin_id'], axis=1, inplace=True)\n",
        "\n",
        "df_timeseries.drop(['Year_Mnth_Day', 'basin_id'], axis=1, inplace=True)\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "print(df_timeseries)\n",
        "for col in df_timeseries.columns:\n",
        "    if col != 'ds' and col !='unique_id':\n",
        "        if col == 'prcp(mm/day)' or col == 'QObs(mm/d)':\n",
        "            df_timeseries[col] = df_timeseries[col].clip(lower=0)\n",
        "            df_timeseries[col] = df_timeseries[col]**(1/3)\n",
        "        df_timeseries[col] = scaler.fit_transform(df_timeseries[[col]])\n",
        "\n",
        "print(df_timeseries)"
      ],
      "metadata": {
        "id": "k9YEO4BPqBTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load chronos\n",
        "pipeline = BaseChronosPipeline.from_pretrained(\n",
        "    \"amazon/chronos-bolt-base\",  # use \"amazon/chronos-bolt-small\" for the corresponding Chronos-Bolt model\n",
        "    device_map=\"cuda\",  # use \"cpu\" for CPU inference\n",
        "    torch_dtype=torch.bfloat16,\n",
        ")\n",
        "\n",
        "\n",
        "# perpare input\n",
        "lookback_length = 21\n",
        "Nloc = 671\n",
        "Ndays = 7031\n",
        "\n",
        "# forecasting configurations\n",
        "forecast_length = 1\n",
        "num_samples = 1           # generate 1 sample\n",
        "\n",
        "timeseries_cols = timeseries_cols[2:]\n",
        "Nprop = len(timeseries_cols)"
      ],
      "metadata": {
        "id": "_d4PQlGNm3Iy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# evaluate model\n",
        "ground_truth = np.zeros((Ndays - lookback_length, ValidationNloc, Nprop))\n",
        "preds = np.zeros((Ndays - lookback_length, ValidationNloc, Nprop))\n",
        "\n",
        "print(ground_truth.shape)\n",
        "\n",
        "iloc = 0\n",
        "\n",
        "if Restorefromcheckpoint:\n",
        "    iloc, ground_truth, preds = restoreCkpt(run_name, ckpt_name)\n",
        "    iloc += 1   # start evaluating the next unchecked location\n",
        "    print(f\"Restored from checkpoint: iloc={iloc}\")\n",
        "\n",
        "\n",
        "# prepare input\n",
        "df = (df_timeseries.set_index(['ds','unique_id']).unstack('unique_id').sort_index())\n",
        "\n",
        "# look at each catchment\n",
        "while iloc < ValidationNloc:\n",
        "    cat_id = ListofValidationLocs[iloc]\n",
        "    # look at each sequence for that catchment\n",
        "    for t in range(Ndays - lookback_length):\n",
        "\n",
        "        # multivariate training\n",
        "\n",
        "        train_data = []\n",
        "        for iprop in range(len(timeseries_cols)):\n",
        "            prop = timeseries_cols[iprop]\n",
        "            train_data.append(torch.tensor(df[prop][cat_id][t: t + lookback_length]))\n",
        "\n",
        "            # update label\n",
        "            ground_truth[t, iloc, iprop] = df[prop][cat_id][t + lookback_length]\n",
        "\n",
        "        forecast = pipeline.predict(\n",
        "            context=train_data,\n",
        "            prediction_length=1,\n",
        "        )\n",
        "\n",
        "        # update preds\n",
        "        preds[t, iloc, :] = forecast[:,4,:].flatten().float()   # Pick middle value\n",
        "    saveCkpt(iloc, ground_truth, preds, run_name, ckpt_name)\n",
        "\n",
        "    iloc += 1\n",
        "    print(f\"Location {iloc} saved to checkpoint\")"
      ],
      "metadata": {
        "id": "SXhQlcP08EE5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# calculate MSE\n",
        "for iprop in range(len(timeseries_cols)):\n",
        "    prop = timeseries_cols[iprop]\n",
        "    mse = np.mean((ground_truth[:, :, iprop] - preds[:, :, iprop])**2)\n",
        "    rmse = np.sqrt(mse)\n",
        "    print(f\"MSE for {prop}: {mse}\")\n",
        "    print(f\"RMSE for {prop}: {rmse}\")"
      ],
      "metadata": {
        "id": "ny4Ug8hpCCuS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# plot\n",
        "fig, axs = plot_numpy(ground_truth[:, :, 0], pred[:, :, 0], f'Chronos precipitation', splitsize=6)"
      ],
      "metadata": {
        "id": "Zy9MLZATs-T7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}